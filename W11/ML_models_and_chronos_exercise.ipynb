{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nepslor/B5203E-TSAF/blob/main/W11/ML_models_and_chronos_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced models for forecasting\n",
        "In this exercise we will see how to run advanced forecasting models\n",
        "* A lightgboost model\n",
        "* [Chronos 2 model](https://arxiv.org/abs/2510.15821)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nepslor/teaching/main/TimeSeriesForecasting/figs/Screenshot_20251201_123940.png\" width=\"900\"/>"
      ],
      "metadata": {
        "id": "lMxnWs8Udh6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPCg6tKY03to"
      },
      "outputs": [],
      "source": [
        "!pip install lightgbm wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9iMa-tPDX_y"
      },
      "outputs": [],
      "source": [
        "\n",
        "import wget\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# Setup path\n",
        "save_folder = 'jena_climate'\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)\n",
        "\n",
        "# Download Data\n",
        "print(\"Downloading data...\")\n",
        "dat = wget.download('https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip', out=save_folder)\n",
        "\n",
        "# Extract\n",
        "with zipfile.ZipFile(dat, 'r') as zip_ref:\n",
        "    zip_ref.extractall(save_folder)\n",
        "\n",
        "# Parse Dates\n",
        "dateparse = lambda x: datetime.strptime(x, '%d.%m.%Y %H:%M:%S')\n",
        "csv_path = os.path.join(save_folder, 'jena_climate_2009_2016.csv')\n",
        "\n",
        "# Load & Resample\n",
        "print(\"\\nProcessing Dataframe...\")\n",
        "df_weather = pd.read_csv(csv_path, parse_dates=['Date Time'], index_col='Date Time', date_parser=dateparse)\n",
        "# Resample to hourly to make the data manageable\n",
        "df_weather = df_weather.resample('1h').mean()\n",
        "\n",
        "# Inspect\n",
        "print(f\"Data loaded. Shape: {df_weather.shape}\")\n",
        "df_weather.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6XXqciAnZik"
      },
      "outputs": [],
      "source": [
        "original_cols = df_weather.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ux5B-TVcJDQ"
      },
      "outputs": [],
      "source": [
        "# @title 1. Data Visualization\n",
        "print('#'*50)\n",
        "print('Shape of dataset: {}'.format(df_weather.shape))\n",
        "print('#'*50)\n",
        "print('Missing vals: {}'.format(df_weather.isna().sum()))\n",
        "print('#'*50)\n",
        "df_weather.iloc[:2000, :].plot(subplots=True, figsize=(20, 10))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds1RZXe_j65y"
      },
      "outputs": [],
      "source": [
        "df_weather['T (degC)'].plot(figsize=(20, 4))\n",
        "df_weather.plot(figsize=(20, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO29bcOnkoI7"
      },
      "outputs": [],
      "source": [
        "ma = df_weather.rolling(window=24*7, center=True, min_periods=1).mean()\n",
        "m_std = df_weather.rolling(window=24*7, center=True, min_periods=1).std()\n",
        "saliency = (df_weather-ma) / m_std\n",
        "saliency.plot(figsize=(20, 4));\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EmnNO53pDf6"
      },
      "outputs": [],
      "source": [
        "outlier = (saliency.abs() > saliency.std()*5) | ((df_weather - df_weather.mean()).abs() > df_weather.std() * 10)\n",
        "\n",
        "df_weather_noo = df_weather.copy()\n",
        "# set outliers to nan, interpolate\n",
        "for variable_key in df_weather.columns:\n",
        "  df_weather_noo.loc[outlier[variable_key], variable_key] = np.nan\n",
        "  df_weather_noo[variable_key] = df_weather_noo[variable_key].interpolate(method='pchip')\n",
        "\n",
        "\n",
        "for variable_key in df_weather.columns:\n",
        "  outlier_days = np.unique([pd.to_datetime(d.date())  for d  in outlier[variable_key].loc[outlier[variable_key]].index])\n",
        "  if len(outlier_days) == 0:\n",
        "    continue\n",
        "  fig, ax = plt.subplots(len(outlier_days), 1, figsize=(15, len(outlier_days)), layout='constrained')\n",
        "  ax = np.atleast_1d(ax)\n",
        "  for a, od in zip(ax.ravel(), outlier_days):\n",
        "    df_weather[variable_key].loc[df_weather.index>=od].iloc[:200].plot(ax=a)\n",
        "    df_weather_noo[variable_key].loc[df_weather_noo.index>=od].iloc[:200].plot(ax=a, linestyle='--')\n",
        "    o_idx = outlier[variable_key].loc[outlier.index>=od].iloc[:200]\n",
        "    o_idx = o_idx[o_idx].index\n",
        "    a.scatter(o_idx, df_weather[variable_key].loc[o_idx], color='red')\n",
        "    a.set_xlabel('')\n",
        "    a.set_xticks([])\n",
        "    a.set_xticklabels([])\n",
        "    a.tick_params(axis='x', bottom=False, labelbottom=False)\n",
        "    # More aggressive tick removal\n",
        "    a.xaxis.set_major_locator(plt.NullLocator())\n",
        "    a.xaxis.set_minor_locator(plt.NullLocator())\n",
        "    a.text(y=0.9, x=0.9, s=od.strftime('%Y-%m-%d'), ha='right', va='top', transform=a.transAxes, fontsize=12)\n",
        "  ax[0].set_title(variable_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rezgFkXedNDv"
      },
      "outputs": [],
      "source": [
        "df_weather_noo.plot(figsize=(20, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE-fvDH9x6te"
      },
      "outputs": [],
      "source": [
        "df_weather = df_weather_noo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoSKNgh_k4nI"
      },
      "outputs": [],
      "source": [
        "# @title 2. Feature generation and embargo split\n",
        "target = 'T (degC)'\n",
        "def add_features(df, target = 'T (degC)'):\n",
        "  df_weather = df.copy()\n",
        "\n",
        "  df_weather['hour'] = df_weather.index.hour\n",
        "  df_weather['day_of_week'] = df_weather.index.dayofweek\n",
        "  df_weather['day_of_year'] = df_weather.index.dayofyear\n",
        "  df_weather['month'] = df_weather.index.month\n",
        "  df_weather['year'] = df_weather.index.year\n",
        "\n",
        "  # Calculate the rolling average of 'T (degC)'\n",
        "  df_weather[f'{target}_rolling_avg_24h'] = df_weather[target].rolling(window=24, min_periods=1).mean()\n",
        "  df_weather[f'{target}_rolling_avg_48h'] = df_weather[target].rolling(window=48, min_periods=1).mean()\n",
        "  df_weather[f'{target}_rolling_avg_72h'] = df_weather[target].rolling(window=72, min_periods=1).mean()\n",
        "  df_weather[f'{target}_daily_mean_7d'] = df_weather[target].rolling(window=24*7, min_periods=1).mean()\n",
        "  df_weather[f'{target}_daily_max_7d'] = df_weather[target].rolling(window=24*7, min_periods=1).max()\n",
        "  df_weather[f'{target}_daily_min_7d'] = df_weather[target].rolling(window=24*7, min_periods=1).min()\n",
        "\n",
        "  # Create 48 lagged features for 'T (degC)'\n",
        "  history = {}\n",
        "  for i in range(1, 24):\n",
        "      history[f'{target}_lag_{i}'] = df_weather[target].shift(i)\n",
        "\n",
        "\n",
        "\n",
        "  # Create 24 targets 'T (degC)'\n",
        "  future = {}\n",
        "  for i in range(1, 49):\n",
        "      future[f'{target}_lag_{-i}'] = df_weather[target].shift(-i)\n",
        "\n",
        "  df_weather = pd.concat([df_weather, pd.DataFrame(history), pd.DataFrame(future)], axis=1)\n",
        "  df_weather.dropna(inplace=True)\n",
        "  return df_weather\n",
        "\n",
        "df_weather = add_features(df_weather_noo, target)\n",
        "print(\"Generated new features. Displaying first 5 rows with new columns:\")\n",
        "print(f\"New shape of df_weather: {df_weather.shape}\")\n",
        "df_weather.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjEfqoKrnKOq"
      },
      "outputs": [],
      "source": [
        "# @title 3 - Train-test split with embargo\n",
        "embargo_period = 24*3\n",
        "n_te = 1000\n",
        "n_cal = 10000\n",
        "df_tr = df_weather.iloc[:-(n_te+n_cal+embargo_period)]\n",
        "df_cal = df_weather.iloc[-(n_te+n_cal+embargo_period):-n_te]\n",
        "df_te = df_weather.iloc[-(n_te+embargo_period):]\n",
        "\n",
        "target_names = [c for c in df_weather.columns if target in c and 'lag_-' in c]\n",
        "x_tr, y_tr = df_tr.drop(columns=target_names), df_tr[target_names]\n",
        "x_cal, y_cal = df_cal.drop(columns=target_names), df_cal[target_names]\n",
        "x_te, y_te = df_te.drop(columns=target_names), df_te[target_names]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVrNvpKSojCE"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def create_pdf(y_cal, y_hat_cal, q_vect = np.arange(11)/10):\n",
        "  err = y_cal - y_hat_cal\n",
        "  q_errs = np.quantile(err, q_vect, axis=0).T\n",
        "  return q_errs\n",
        "\n",
        "class Multi_reg:\n",
        "  def __init__(self, model_class) -> None:\n",
        "     self.model_class = model_class\n",
        "     self.models = []\n",
        "\n",
        "  def fit(self, x, y, budget=10000):\n",
        "    rnd_idx = np.random.choice(x.index, size=budget, replace=False)\n",
        "    for c in tqdm(y.columns, 'fitting'):\n",
        "      model = self.model_class()\n",
        "      model.fit(x.loc[rnd_idx, :], y[c].loc[rnd_idx])\n",
        "      self.models.append(model)\n",
        "\n",
        "  def predict(self, x):\n",
        "    preds = []\n",
        "    for model in tqdm(self.models, 'predicting'):\n",
        "      preds.append(model.predict(x))\n",
        "    return np.array(preds).T\n",
        "\n",
        "forecas_classes = [LinearRegression, LGBMRegressor]\n",
        "\n",
        "ys_hat_te = {}\n",
        "qs_hat_te = {}\n",
        "for f in forecas_classes:\n",
        "  m = Multi_reg(partial(f))\n",
        "  m.fit(x_tr, y_tr)\n",
        "  y_hat_cal = m.predict(x_cal)\n",
        "  ys_hat_te[f.__name__] = m.predict(x_te)\n",
        "  q_errs = create_pdf(y_cal, y_hat_cal, q_vect = np.arange(11)/10)\n",
        "  qs_hat_te[f.__name__] = np.expand_dims(ys_hat_te[f.__name__], 2) + np.expand_dims(q_errs, 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g23-MqtGYoDA"
      },
      "outputs": [],
      "source": [
        "#@title  Fast Quantile Plot\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "def qs_animation_plotly(y_te, y_hat, qs, n_rows=50, f_name=''):\n",
        "    \"\"\"\n",
        "    y_te:  (n_samples, T)\n",
        "    y_hat: (n_samples, T)\n",
        "    qs:    (n_samples, T, n_quantiles)\n",
        "    \"\"\"\n",
        "\n",
        "    t = np.arange(y_te.shape[1])\n",
        "    n_quant = qs.shape[2]\n",
        "\n",
        "    # --- INITIAL FRAME ---\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # true\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=t, y=y_te[0],\n",
        "        mode=\"lines\",\n",
        "        line=dict(color=\"blue\", width=2),\n",
        "        name=\"y_te\"\n",
        "    ))\n",
        "\n",
        "    # predicted\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=t, y=y_hat[0],\n",
        "        mode=\"lines\",\n",
        "        line=dict(color=\"orange\", width=2),\n",
        "        name=\"y_hat\"\n",
        "    ))\n",
        "\n",
        "    # quantile curves\n",
        "    for j in range(n_quant):\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=t, y=qs[0, :, j],\n",
        "            mode=\"lines\",\n",
        "            line=dict(color=\"red\", width=1),\n",
        "            opacity=0.3,\n",
        "            name=f\"q{j}\",\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "    # --- FRAMES ---\n",
        "    frames = []\n",
        "    for i in range(n_rows):\n",
        "        frame_data = [\n",
        "            go.Scatter(y=y_te[i]),\n",
        "            go.Scatter(y=y_hat[i]),\n",
        "        ]\n",
        "        # quantiles\n",
        "        frame_data.extend(\n",
        "            [go.Scatter(y=qs[i, :, j]) for j in range(n_quant)]\n",
        "        )\n",
        "        frames.append(go.Frame(data=frame_data, name=f\"frame{i}\"))\n",
        "\n",
        "    fig.frames = frames\n",
        "\n",
        "    # --- LAYOUT WITH PLAY BUTTON ---\n",
        "    fig.update_layout(\n",
        "        height=500,\n",
        "        width=400,\n",
        "        title=\"Quantile Forecast Animation for {}\".format(f_name),\n",
        "        updatemenus=[{\n",
        "            \"type\": \"buttons\",\n",
        "            \"buttons\": [\n",
        "                {\n",
        "                    \"label\": \"Play\",\n",
        "                    \"method\": \"animate\",\n",
        "                    \"args\": [\n",
        "                        None,\n",
        "                        {\n",
        "                            \"frame\": {\"duration\": 50, \"redraw\": True},\n",
        "                            \"fromcurrent\": True,\n",
        "                            \"transition\": {\"duration\": 0}\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }]\n",
        "    )\n",
        "\n",
        "    # y-axis limits\n",
        "    y_min = min(np.min(y_te), np.min(qs)) - 1\n",
        "    y_max = max(np.max(y_te), np.max(qs)) + 1\n",
        "    fig.update_yaxes(range=[y_min, y_max])\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx1gkzJGuMvP"
      },
      "outputs": [],
      "source": [
        "keys = list(qs_hat_te.keys())\n",
        "skip = 24*7\n",
        "for k in keys:\n",
        "  display(qs_animation_plotly(y_te.values[skip:], ys_hat_te[k][skip:], qs_hat_te[k][skip:], n_rows=400, f_name=k))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO4reGG8him_"
      },
      "outputs": [],
      "source": [
        "%pip install 'chronos-forecasting>=2.1' 'pandas[pyarrow]' 'matplotlib'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDeMMR8SiKM8"
      },
      "outputs": [],
      "source": [
        "x_te_cr = x_te[original_cols].copy().reset_index()\n",
        "x_te_cr['item_id'] = 'temp'\n",
        "x_te_cr.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbQzC-nsho0h"
      },
      "outputs": [],
      "source": [
        "from chronos import BaseChronosPipeline, Chronos2Pipeline\n",
        "\n",
        "pipeline: Chronos2Pipeline = BaseChronosPipeline.from_pretrained(\"amazon/chronos-2\", device_map=\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRrhBbqHjMjU"
      },
      "outputs": [],
      "source": [
        "# Generate predictions with covariates\n",
        "def predict_chronos(x_te_cr, n=400, n_context = 24*7):\n",
        "  cron_qs=[0.01, 0.1, 0.2, 0.5, 0.7, 0.8, 0.9, 0.99]\n",
        "  w = np.arange(n_context)\n",
        "  preds = []\n",
        "  quantiles = []\n",
        "  for i in tqdm(range(n)):\n",
        "    df_context = x_te_cr.loc[w+i]\n",
        "    cron_pred_df = pipeline.predict_df(\n",
        "        df_context,\n",
        "        prediction_length=48,\n",
        "        quantile_levels=cron_qs,\n",
        "        id_column=\"item_id\",\n",
        "        timestamp_column=\"Date Time\",\n",
        "        target=target,\n",
        "    )\n",
        "    preds.append(cron_pred_df['predictions'])\n",
        "    quantiles.append(cron_pred_df[[str(q) for q in cron_qs]].values)\n",
        "  y_hat_te = pd.concat(preds, axis=1).T\n",
        "  q_hat_te = np.rollaxis(np.dstack(quantiles), 2)\n",
        "  return y_hat_te, q_hat_te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMkD5jLOq3tS"
      },
      "outputs": [],
      "source": [
        "n_rows = 400 # Number of samples to animate, matching the number of predictions made by Chronos\n",
        "n_context = 24*7\n",
        "y_hat_te, q_hat_te = predict_chronos(x_te_cr, n_context = n_context, n=n_rows)\n",
        "display(qs_animation_plotly(y_te.values[n_context : n_context + n_rows], y_hat_te.values, q_hat_te, n_rows=n_rows, f_name='cronos2'))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}