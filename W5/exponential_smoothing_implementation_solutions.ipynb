{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nepslor/B5203E-TSAF/blob/main/W5/exponential_smoothing_implementation_solutions.ipynb)"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exponential smoothing implementation\n",
    "In this exercise we will try to craft different flavours of exponential smoothing algorithms from scratch, and compare their performance.\n",
    "\n"
   ],
   "metadata": {
    "id": "kQro5qKqN4YN"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4KQLHSkswDv7"
   },
   "source": [
    "%%capture\n",
    "!pip install wget\n",
    "import pandas as pd\n",
    "import wget\n",
    "import numpy as np\n",
    "data = pd.read_pickle(wget.download(\"https://zenodo.org/record/4549296/files/reduced_dataset.pk?download=1\"));"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "samples_per_day = 24\n",
    "data = pd.concat([data['all'], pd.Series(np.vstack(data['ghi_backwards'])[:, 0], name='ghi', index=data.index), pd.Series(np.vstack(data['temperature'])[:, 0], name='T', index=data.index)], axis=1)\n",
    "data = data.resample('1h', origin='start').mean()\n",
    "data /= data.std()\n",
    "data = data.iloc[48:]\n",
    "data.head()\n",
    "\n"
   ],
   "metadata": {
    "id": "-SzZEQcvwMEC"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 4))\n",
    "_ = sm.graphics.tsa.plot_acf(data['all'], lags=24*7, ax=ax[0])\n",
    "\n",
    "y = data['all'].loc[data.index<'2019-01-13']\n",
    "y = pd.concat([y, pd.Series(y.index.dayofyear, name='day', index=y.index),\n",
    "               pd.Series(y.index.hour, name='hour', index=y.index)], axis=1)\n",
    "y_mat = y.pivot(index='day', columns='hour', values='all').T\n",
    "ax[1].matshow(y_mat, aspect='auto')\n",
    "\n"
   ],
   "metadata": {
    "id": "ZFjE3tICwuJL"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the ACF plot it is clear that the signal is strongly seasonal, with a period of 24 hours. The heatmap plot also shows that the signal has a daily seasonality, with higher values during the day and lower values during the night. Let's keep a seasonality = 24 for our models.\n",
    "\n",
    "In the following we just define an auxiliary function for showing some animations. It accepts a pd.DataFrame of ground truth values and a numpy matrix of predictions\n"
   ],
   "metadata": {
    "id": "elZLY36_DCBP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def ts_animation(y_te, y_hat, n_rows=50, labels=None):\n",
    "  \"plot the first n_rows of the two y_te and y_hat matrices\"\n",
    "  if labels is None:\n",
    "    labels = ['1', '2']\n",
    "  fig, ax = plt.subplots(1);\n",
    "  y_min = np.minimum(np.min(y_hat), np.min(y_te))\n",
    "  y_max = np.maximum(np.max(y_hat), np.max(y_te))\n",
    "  line1, = ax.plot(y_hat[0], lw=2, label=labels[0]);\n",
    "  line2, = ax.plot(y_hat[0], lw=2, label=labels[1]);\n",
    "  plt.legend()\n",
    "  ax.set_ylim(y_min, y_max)\n",
    "  n_sa = y_hat.shape[1]\n",
    "  def animate(i):\n",
    "    line1.set_data(np.arange(n_sa),y_te[i:i+n_sa]);\n",
    "    line2.set_data(np.arange(n_sa),y_hat[i,:]);\n",
    "    return (line1,line2)\n",
    "\n",
    "  def init():\n",
    "    line1.set_data([], []);\n",
    "    return (line1,)\n",
    "\n",
    "  ani = animation.FuncAnimation(fig, animate, init_func=init, frames=n_rows, interval=100,\n",
    "                                blit=True)\n",
    "  plt.close('all')\n",
    "  #rc('animation', html='jshtml')\n",
    "  return HTML(ani.to_jshtml())\n"
   ],
   "metadata": {
    "id": "BawgE6A98_d-"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## Simple exponential smoothing\n",
    "The following code implements a simple exponential smoothing, with no trend nor seasonality:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "& \\hat{y}_{t+h \\mid t}=\\ell_t \\\\\n",
    "& \\ell_t=\\alpha y_t+(1-\\alpha) \\ell_{t-1}\n",
    "\\end{aligned}$$\n",
    "\n",
    "â“ Try to see the effect of the parameter alpha on the model's forecast. What do you observe?\n"
   ],
   "metadata": {
    "id": "PAdRIz6oDT27"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def simple_smoothing(y, h=1, alpha=0.8):\n",
    "  y_hat = y.iloc[0]\n",
    "  for y_i in y.values:\n",
    "    y_hat = alpha*y_i + (1-alpha)*y_hat\n",
    "  return np.tile(y_hat, h)\n",
    "\n",
    "\n",
    "y_hat = []\n",
    "for i in range(100):\n",
    "  y_hat.append(simple_smoothing(data['all'].iloc[:np.maximum(1, i)], 24))\n",
    "y_hat = np.vstack(y_hat)\n",
    "\n",
    "ts_animation(data['all'].iloc[:100], y_hat, labels=['ground truth', 'predictions'])\n"
   ],
   "metadata": {
    "id": "NEluLKrpzZhW"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_hat = []\n",
    "for i in range(100):\n",
    "  y_hat.append(simple_smoothing(data['all'].iloc[:np.maximum(1, i)], 24, alpha=0.2))\n",
    "y_hat = np.vstack(y_hat)\n",
    "\n",
    "ts_animation(data['all'].iloc[:100], y_hat, labels=['ground truth', 'predictions'])"
   ],
   "metadata": {
    "id": "nQUyDLm26ox_"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Holt's linear trend\n",
    "We can additionally model the trend to have a linear expression for the forecasts, as a function of the step ahead. This makes the model more expressive but it can also lead to over or undershoot the prediction for high step ahead. Try to explore the combinations of the $\\alpha$ and $\\beta$ parameters\n",
    "\n",
    "\\begin{aligned}\n",
    "& \\hat{y}_{t+h \\mid t}=\\ell_t+h b_t \\\\\n",
    "& \\ell_t=\\alpha y_t+(1-\\alpha)\\left(\\ell_{t-1}+b_{t-1}\\right) \\\\\n",
    "& b_t=\\beta^*\\left(\\ell_t-\\ell_{t-1}\\right)+\\left(1-\\beta^*\\right) b_{t-1}\n",
    "\\end{aligned}"
   ],
   "metadata": {
    "id": "L0W5XO1j6vPf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def holt_smoothing(y, h=1, alpha=0.8, beta=0.1):\n",
    "  l, l_past = y.iloc[0], y.iloc[0]\n",
    "  b = 0\n",
    "  for y_t in y.values:\n",
    "    l = alpha*y_t + (1-alpha)*(l_past+b)\n",
    "    b = beta*(l-l_past) + (1-beta)*b\n",
    "    l_past = l\n",
    "\n",
    "  return l + b*np.arange(h)"
   ],
   "metadata": {
    "id": "4o_dGTSJ6t_u"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "y_hat = []\n",
    "for i in range(100):\n",
    "  y_hat.append(holt_smoothing(data['all'].iloc[:np.maximum(1, i)], 24, alpha=0.9, beta=0.05))\n",
    "y_hat = np.vstack(y_hat)\n",
    "\n",
    "ts_animation(data['all'].iloc[:100], y_hat, labels=['ground truth', 'predictions'])"
   ],
   "metadata": {
    "id": "8qt_bq0l78Mx"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Holt Winter\n",
    "Since we have seen that the signal we are trying to forecast is strongly seasonal, we can try to model it using the Holt-Winter model, which also estimate a seasonal component.\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\\hat{y}_{t+h \\mid t} & =\\ell_t+h b_t+s_{index + h} \\\\\n",
    "\\ell_t & =\\alpha\\left(y_t-s_{t-m}\\right)+(1-\\alpha)\\left(\\ell_{t-1}+b_{t-1}\\right) \\\\\n",
    "b_t & =\\beta^*\\left(\\ell_t-\\ell_{t-1}\\right)+\\left(1-\\beta^*\\right) b_{t-1} \\\\\n",
    "s_{index} & =\\gamma\\left(y_t-\\ell_{t-1}-b_{t-1}\\right)+(1-\\gamma) s_{index}\n",
    "\\end{aligned}\n",
    "where $index = t \\mod m$ and $m$ is the period of the seasonality. The seasonal component is stored in a vector $s$ of length $m$. The parameters $\\alpha$, $\\beta$ and $\\gamma$ are the smoothing parameters for the level, trend and seasonality respectively.\n",
    "### â“ HW model\n",
    "Try to complete the estimation for the seasonal components used by the HW method. As you can see from the code, $s$ is a vector containing the estimated values for the seasonal profile."
   ],
   "metadata": {
    "id": "80VezElvD1Tp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def holt_winters(y, s_init=None, h=1, alpha=0.8, beta=0.1, gamma=0.1, m=24, return_s=False):\n",
    "  \"\"\"\n",
    "  h: steps ahead to be predicted\n",
    "  m: period of the seasonality\n",
    "  \"\"\"\n",
    "  l, l_past = 0, 0\n",
    "  s = s_init.copy() if s_init is not None else np.zeros(m)\n",
    "  b = 0\n",
    "  for t, y_t in enumerate(y):\n",
    "    index = t%m\n",
    "    s[index] = gamma*(y_t-l_past-b) + (1-gamma)*s[index-m]\n",
    "    l = alpha*(y_t-s[index]) + (1-alpha)*(l_past+b)\n",
    "    b = beta*(l-l_past) + (1-beta)*b\n",
    "    l_past = l\n",
    "\n",
    "  # roll the seasonal component and take just the relevant part\n",
    "  seasonal = np.roll(s, -index)[:h]\n",
    "\n",
    "  # prediction equation\n",
    "  preds = l + b*np.arange(h) + seasonal\n",
    "\n",
    "  if return_s:\n",
    "    return preds, s\n",
    "  else:\n",
    "    return preds\n",
    "\n"
   ],
   "metadata": {
    "id": "25sNPZJbBzTn"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see the model's prediction when all states are initialized with zero values:"
   ],
   "metadata": {
    "id": "8Xv9iyAXaCq0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "m = 24\n",
    "\n",
    "y_hat = []\n",
    "seasonal_state = []\n",
    "for i in range(600):\n",
    "  preds, s = holt_winters(data['all'].iloc[:np.maximum(1, i)].copy().values, h=24, alpha=0.1, beta=0.01, gamma=0.2, m=24, return_s=True)\n",
    "  y_hat.append(preds)\n",
    "  seasonal_state.append(s)\n",
    "\n",
    "y_hat = np.vstack(y_hat)\n",
    "seasonal_state = np.vstack(seasonal_state)\n",
    "\n",
    "\n",
    "ts_animation(data['all'].values, y_hat, 100, labels=['ground truth', 'predictions'])\n"
   ],
   "metadata": {
    "id": "2jl6JUdODIG0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next cell shows the HW's \"learning\" of the seasonality state vector. It seems that initializing this state could be helpful."
   ],
   "metadata": {
    "id": "wRzXUdGEaRSV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ts_animation(data['all'].values, seasonal_state, 200, labels=['ground truth', 'seasonal component'])"
   ],
   "metadata": {
    "id": "dYX-2mJZYwt2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the next cell we use the s_init argument to pass the first day of observations to the model, to initialize the values in s"
   ],
   "metadata": {
    "id": "XqI4LSkvaja9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "m = 24\n",
    "\n",
    "y_hat = []\n",
    "s_init = data['all'].iloc[:m].copy().values\n",
    "\n",
    "for i in range(600):\n",
    "  y_hat.append(holt_winters(data['all'].iloc[:np.maximum(1, i)].values, s_init=s_init,  h=24, alpha=0.1, beta=0.01, gamma=0.2, m=24))\n",
    "y_hat = np.vstack(y_hat)\n",
    "\n",
    "ts_animation(data['all'].values, y_hat, 150)"
   ],
   "metadata": {
    "id": "GK9xvGNmEH0B"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# â“ Optimal parameters\n",
    "Let's try to find the optimal parameters for the Holt winter model. You can use any optimization technique to find the optimal values.\n",
    "So far we didn't *fit* the model's parameters, we just set them manually. Let's try to find the optimal values for the parameters $\\alpha$, $\\beta$ and $\\gamma$ by minimizing the RMSE over a training set. We will then test the model on a test set.\n",
    "### Scoring strategy\n",
    "We could just compute the RMSE on one forecasting window (24 hours) and tune the parameters to minimize this error. However, *this will lead to overfitting the parameters to a specific window*. In this course is severely forbidden ðŸ˜‰!\n",
    "\n",
    "To have a more robust estimate of the parameters, we will use a rolling forecasting origin strategy with a *fit once* procedure:\n",
    "1) First, we fit the model once on a training set\n",
    "2) We will compute the RMSE over multiple forecasting windows on a test set, and then average the RMSEs to get a more robust estimate of the model's performance.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/nepslor/B5203E-TSAF/main/pics/time-series-backtesting-forecasting-no-refit.gif\" width=\"600\">"
   ],
   "metadata": {
    "id": "DRXRtrMx4O2X"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tr_ratio = 0.2\n",
    "n_tr = int(len(data)*tr_ratio)\n",
    "df_tr = data['all'].iloc[:n_tr]\n",
    "df_te = data['all'].iloc[n_tr:]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def get_scores(y, n_steps, n_sa, alpha, beta, gamma, m=24):\n",
    "  y_hat = []\n",
    "  y_np = y.values.ravel()\n",
    "  scores = np.zeros(n_steps)\n",
    "  s_init = data['all'].iloc[:m].values\n",
    "  # What does this code do?\n",
    "  for i in range(n_steps):\n",
    "    y_hat = holt_winters(np.copy(y_np[:np.maximum(1, i)]), s_init,  n_sa, alpha=alpha, beta=beta, gamma=gamma, m=m)\n",
    "    errs = y_hat-y_np[np.maximum(1, i):np.maximum(1, i)+n_sa]\n",
    "    scores[i] = np.mean(errs**2)**0.5\n",
    "  return np.mean(scores)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "n_trials = 500\n",
    "pars = np.random.rand(n_trials, 3)\n",
    "scores = np.zeros(n_trials)\n",
    "print('start fitiing')\n",
    "for n in tqdm(range(n_trials)):\n",
    "    alpha, beta, gamma = pars[n, :]\n",
    "    scores[n] = get_scores(df_tr, 500, 24, alpha, beta, gamma)"
   ],
   "metadata": {
    "id": "eV5fvZdIhAml"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now have a look at the predictions of the best model"
   ],
   "metadata": {
    "id": "l5XqTUp4A8n1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "best_pars = pars[np.argmin(scores), :]\n",
    "print('best pars: {}, {} ,{}'.format(*best_pars))\n",
    "\n",
    "y_hat = []\n",
    "y_np = df_te.values.ravel()\n",
    "s_init = df_te.iloc[:m].copy().values\n",
    "for i in range(600):\n",
    "  y_hat.append(holt_winters(y_np[:np.maximum(1, i)], s_init, 24, alpha=best_pars[0], beta=best_pars[1], gamma=best_pars[2]))\n",
    "y_hat = np.vstack(y_hat)\n",
    "ts_animation(df_te.iloc[200:], y_hat[200:, :], 200)"
   ],
   "metadata": {
    "id": "FmQzuNPeidl-"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(np.sort(scores))\n",
    "plt.xlabel('parameter tested sorted by score')\n",
    "plt.ylabel('RMSE')"
   ],
   "metadata": {
    "id": "h7QpKlK8juZH"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modified Holt Winters\n",
    "In the following cell we introduce an additional state, the last step error made by the HW forecaster. This error is subtracted for the estimation of the level and seasonality, and added to the prediction with an exponential decreasing influence over the prediction horizon"
   ],
   "metadata": {
    "id": "y5RWAbl2e1_u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def modified_holt_winters(y, s_init=None, h=1, alpha=0.8, beta=0.1, gamma=0.1, omega=0.9, m=24, return_s=False):\n",
    "  \"\"\"\n",
    "  h: steps ahead to be predicted\n",
    "  m: period of the seasonality\n",
    "  \"\"\"\n",
    "  l, l_past = 0, 0\n",
    "  s = s_init.copy() if s_init is not None else np.zeros(m)\n",
    "  b = 0\n",
    "  eps = 0\n",
    "  for t, y_t in enumerate(y):\n",
    "    index = t%m\n",
    "    s[index] = gamma*(y_t-l_past-b-eps) + (1-gamma)*s[index]\n",
    "    l = alpha*(y_t-s[index]-eps) + (1-alpha)*(l_past+b)\n",
    "    b = beta*(l-l_past) + (1-beta)*b\n",
    "    eps = omega * (y_t-l_past-b-s[index]) + (1-omega) * eps\n",
    "    l_past = l\n",
    "\n",
    "  preds = l + b*np.arange(h) + np.hstack([s[index:], s[:index]])[:h] + eps*(h-np.arange(h))**2/h**2\n",
    "  if return_s:\n",
    "    return preds, s\n",
    "  else:\n",
    "    return preds\n",
    "\n",
    "\n",
    "m = 24\n",
    "\n",
    "y_hat = []\n",
    "seasonal_state = []\n",
    "s_init = data['all'].iloc[:m].copy().values\n",
    "for i in range(600):\n",
    "  preds, s = modified_holt_winters(data['all'].iloc[:np.maximum(1, i)].copy().values, h=24, alpha=best_pars[0], beta=best_pars[1], gamma=best_pars[2], m=24, return_s=True, s_init=s_init)\n",
    "  y_hat.append(preds)\n",
    "  seasonal_state.append(s)\n",
    "\n",
    "y_hat = np.vstack(y_hat)\n",
    "seasonal_state = np.vstack(seasonal_state)\n",
    "\n",
    "\n",
    "ts_animation(data['all'].values[200:], y_hat[200:, :], 200, labels=['ground truth', 'predictions'])"
   ],
   "metadata": {
    "id": "SPTNJsXPe6Cd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra: sensitivity analysis of the parameter importance"
   ],
   "metadata": {
    "id": "MyH_bpH2Eyzn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_scores = pd.DataFrame(np.hstack([pars,scores.reshape(-1, 1)]), columns=['alpha', 'beta', 'gamma', 'score']).sort_values('score')\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "v_min = df_scores['score'].min()\n",
    "v_max = df_scores['score'].max()\n",
    "from matplotlib.colors import PowerNorm\n",
    "norm = PowerNorm(gamma=0.1, vmin=v_min, vmax=v_max)\n",
    "ax[0].scatter(df_scores['alpha'], df_scores['beta'], c=df_scores['score'], cmap='viridis', norm=norm, s=2)\n",
    "ax[0].set_xlabel('alpha')\n",
    "ax[0].set_ylabel('beta')\n",
    "ax[1].scatter(df_scores['beta'], df_scores['gamma'], c=df_scores['score'], cmap='viridis', norm=norm, s=2)\n",
    "ax[1].set_xlabel('beta')\n",
    "ax[1].set_ylabel('gamma')\n",
    "ax[2].scatter(df_scores['alpha'], df_scores['gamma'], c=df_scores['score'], cmap='viridis', norm=norm, s=2)\n",
    "ax[2].set_xlabel('alpha')\n",
    "ax[2].set_ylabel('gamma')\n"
   ],
   "metadata": {
    "id": "pB7PIVl3EyEK"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Nixtla statsforecast implementation\n",
    "Nixtla provides an efficient implementation of many forecasting models, including the AutoETS class: https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#autoets. Let's see how it performs on our dataset.\n",
    "The AutoETS class automatically selects the best exponential smoothing model for the data, based on the AICc criterion. The class search among the exponential smoothing models based on three components: error, trend and seasonality. Each component can be additive (A), multiplicative (M) or none (N). The model is specified by a three letter string, where the first letter indicates the error type, the second letter the trend type and the third letter the seasonality type. For example, the model 'AAA' indicates an additive error, additive trend and additive seasonality. The model 'MNN' indicates a multiplicative error, no trend and no seasonality.\n",
    "If the components are set to 'Z', the class will automatically select the best component type based on the AICc criterion. For example, the model 'ZZZ' indicates that the class will automatically select the best error, trend and seasonality types.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoETS\n",
    "model = AutoETS(season_length=24, model='ZZZ')\n",
    "fitted_model = model.fit(df_tr.values)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can implement our *fit once* and rolling forecasting origin strategy by using the `.forward` method of the StatsForecast class. This method accepts as input the time series up to the last timestep, and the number of steps ahead to be predicted."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_hat = []\n",
    "for i in range(200):\n",
    "    y_past = np.hstack([df_tr.values, df_te.iloc[:i].values])\n",
    "    preds = fitted_model.forward(y_past, h=24)\n",
    "    y_hat.append(preds['mean'])\n",
    "y_hat = np.vstack(y_hat)\n",
    "ts_animation(df_te, y_hat, 200)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
