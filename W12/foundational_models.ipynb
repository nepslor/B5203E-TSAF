{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nepslor/B5203E-TSAF/blob/main/W9/foundational_models.ipynb)"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fundational models\n",
    "One of the most influential developments in deep learning has been the transformer architecture, introduced in Attention Is All You Need (Vaswani et al. 2017). Unlike traditional recurrent neural networks (RNNs) or long short-term memory (LSTM) networks, transformers process entire input sequences in parallel rather than sequentially. This eliminates the need for step-by-step recurrence, making them more scalable and efficient for large datasets.\n",
    "\n",
    "In this exercise we will run two fundational models for:\n",
    "* transfer learning\n",
    "* predicting with covariates\n",
    "\n"
   ],
   "metadata": {
    "id": "PIVWBqjV8VX6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install numpy==1.26.4 pandas==2.1.4\n",
    "!pip install matplotlib ipython python-dotenv\n",
    "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install nixtla\n",
    "!pip install fpppy uni2ts\n",
    "!pip install gluonts==0.14.4"
   ],
   "metadata": {
    "id": "mM4NHmdJaEtT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "❗ Due to incompatibility issues, you must restart the session now! `Runtime --> Restart Session`\n"
   ],
   "metadata": {
    "id": "JEKKvgDCkUa3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install datasetsforecast neuralforecast\n",
    "!pip install transformers==4.31.0"
   ],
   "metadata": {
    "id": "lvldKBCDits2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTuBr033Z-hT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from nixtla import NixtlaClient\n",
    "from dotenv import load_dotenv\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mae\n",
    "from datasetsforecast.m4 import M4\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import NHITS\n",
    "from neuralforecast.utils import AirPassengersDF\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "mpl.rcParams['axes.prop_cycle'] = cycler(color=[\"#000000\", \"#000000\"])\n",
    "\n",
    "os.environ[\"NIXTLA_ID_AS_COL\"] = \"true\"\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "from fpppy.utils import plot_series"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transfer learinig\n",
    "Transfer-learning refers to pre-training a model on a (usually large) source dataset to improve its performance on a new forecasting task with a target dataset.\n",
    "\n",
    "The core idea of a foundation models is to leverage this principle by training it on large time series dataset, leveraging scaling laws on the dataset and model sizes. A diverse dataset, in terms of breadth and depth is necessary for the model to perform in a wide variety of domains.\n",
    "\n",
    "\n",
    "In the following simple example we illustrate this process by pre-training the NHITS (Challu et al. 2023) on the M4 monthly dataset. The M4 dataset is a collection of 100,000 time series\n",
    "\n",
    "Key techniques implemented in NHiTS (Neural Hierarchical Interpolation for Time Series Forecasting)\n",
    "\n",
    "* Multi-Rate Data Sampling\n",
    "* Neural Basis Expansion Analysis\n",
    "* Doubly Residual Stacking\n",
    "* Hierarchical Interpolation\n",
    "\n",
    "<img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd520fbc5-2ad3-4751-88e4-67280423de22_700x454.png\" width=\"500\"/>\n",
    "\n"
   ],
   "metadata": {
    "id": "_b6mEzeI-CjO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Y_df, _, _ = M4.load(directory=\"./\", group=\"Monthly\")\n",
    "Y_df[\"ds\"] = Y_df.groupby(\"unique_id\")[\"ds\"].transform(\n",
    "    lambda x: pd.date_range(start=\"1970-01-01\", periods=len(x), freq=\"MS\")\n",
    ")\n",
    "Y_df.head()"
   ],
   "metadata": {
    "id": "RBsQi7V_bhby"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fitting on M4"
   ],
   "metadata": {
    "id": "hGhoCrP--m9k"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "horizon = 12\n",
    "stacks = 3\n",
    "models = [\n",
    "    NHITS(\n",
    "        input_size=5 * horizon,\n",
    "        h=horizon,\n",
    "        max_steps=2_000,\n",
    "        stack_types=stacks * [\"identity\"],\n",
    "        n_blocks=stacks * [1],\n",
    "        mlp_units=[[256, 256] for _ in range(stacks)],\n",
    "        n_pool_kernel_size=stacks * [1],\n",
    "        batch_size=32,\n",
    "        scaler_type=\"standard\",\n",
    "        n_freq_downsample=[12, 4, 1],\n",
    "    )\n",
    "]\n",
    "\n",
    "nf = NeuralForecast(models=models, freq=\"M\")\n",
    "nf.fit(df=Y_df)\n"
   ],
   "metadata": {
    "id": "Dnqi-vTlbmUq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicting AirPassengers"
   ],
   "metadata": {
    "id": "gpjEJBjx-pSl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "air_passengers_df = AirPassengersDF.copy()\n",
    "transfer_preds = nf.predict(df=air_passengers_df)\n",
    "\n",
    "\n",
    "plot_series(air_passengers_df, transfer_preds,\n",
    "            xlabel=\"Month\", ylabel=\"Number of passengers\",\n",
    "            title = \"International airline passengers\",\n",
    "            rm_legend=False,)"
   ],
   "metadata": {
    "id": "ZpAWHFcznPvX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Probabilistic forecasts with exogenous variables with Moirai\n",
    "Moirai is an encoder-only transformer model developed by Salesforce. It is a probabilistic model that also relies on patching the input series. It supports both historical and future exogenous variables. A disctinct feature of Moirai is that it uses a mixture distribution, using four different distributions, to output more flexible prediction intervals. Its release also comes with LOTSA, an open archive of time series data with 27B data points.\n",
    "\n",
    "\n",
    "<img src=\"https://otexts.com/fpppy/nbs/15-foundation-models_files/figure-html/fig-moirai-output-1.png\" width=\"800\"/>"
   ],
   "metadata": {
    "id": "pYGYxKy7_BiB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " First, we start by converting the dataset to a GluonTS dataset.\n",
    "\n"
   ],
   "metadata": {
    "id": "EJHknbi7_osC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"https://otexts.com/fpppy/data/electricity_short.csv\", parse_dates=[\"ds\"])\n",
    "df.head()"
   ],
   "metadata": {
    "id": "GuLLOoX7fQ8I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "future_ex_vars_df = pd.read_csv(\n",
    "    \"https://otexts.com/fpppy/data/electricity_future_vars.csv\", parse_dates=[\"ds\"]\n",
    ")\n",
    "future_ex_vars_df.head()"
   ],
   "metadata": {
    "id": "fcIXV-lHfZnG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "full_df = pd.concat([df, future_ex_vars_df], axis=0)\n",
    "full_df = full_df.set_index(\"ds\")\n",
    "\n",
    "ds = PandasDataset.from_long_dataframe(\n",
    "    full_df,\n",
    "    target=\"y\",\n",
    "    item_id=\"unique_id\",\n",
    "    feat_dynamic_real=[\n",
    "        \"Exogenous1\",\n",
    "        \"Exogenous2\",\n",
    "        \"day_0\",\n",
    "        \"day_1\",\n",
    "        \"day_2\",\n",
    "        \"day_3\",\n",
    "        \"day_4\",\n",
    "        \"day_5\",\n",
    "        \"day_6\",\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "id": "YhYqZAaYfi_q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We set the forecast horizon to 24 time steps into the future.\n",
    "\n"
   ],
   "metadata": {
    "id": "f-8Gy2kIWooa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train, test_template = split(ds, offset=-24)\n",
    "test_data = test_template.generate_instances(\n",
    "    prediction_length=24,\n",
    "    windows=1,\n",
    "    distance=24,\n",
    ")"
   ],
   "metadata": {
    "id": "aoQD5dIrfm14"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we initialize the Moirai model. We can choose between small, base and large. Here, let’s use the large model.\n",
    "\n"
   ],
   "metadata": {
    "id": "kfugFvzxWmjB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = MoiraiForecast(\n",
    "    module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-large\"),\n",
    "    prediction_length=24,\n",
    "    context_length=240,\n",
    "    patch_size=\"auto\",\n",
    "    num_samples=50,\n",
    "    target_dim=1,\n",
    "    feat_dynamic_real_dim=ds.num_feat_dynamic_real,\n",
    "    past_feat_dynamic_real_dim=ds.num_past_feat_dynamic_real,\n",
    ")"
   ],
   "metadata": {
    "id": "SZUEB-GpfqHe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the model is initialized, we can use it for zero-shot forecasting with the available exogenous features."
   ],
   "metadata": {
    "id": "6ubMorZmWjPm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predictor = model.create_predictor(batch_size=32)\n",
    "forecasts = predictor.predict(test_data.input)\n",
    "forecasts = list(forecasts)"
   ],
   "metadata": {
    "id": "YBrzx8dSfrny"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "forecasts[0]"
   ],
   "metadata": {
    "id": "qBfqm7qzpl4z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since Moirai is a probabilistic model, it returns a distribution of future values. Thus, let’s take the median as the point forecast."
   ],
   "metadata": {
    "id": "4XhT_IwIWfz_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "moirai_preds = np.median(forecasts[0].samples, axis=0)"
   ],
   "metadata": {
    "id": "JUFx5K9TfuCF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fcst_df = pd.DataFrame({'unique_id':np.tile('NP', 24), 'ds':pd.date_range(df['ds'].iloc[-1], periods=24, freq='1h'), 'moirai':moirai_preds})\n",
    "plot_series(df, fcst_df, max_insample_length=100,\n",
    "            xlabel=\"Hour\", ylabel=\"Price\",\n",
    "            title=\"Electricity price of the Nord Pool electricity market\",\n",
    "            rm_legend=False)"
   ],
   "metadata": {
    "id": "FwcvUyM5fwTa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also plot the different samples:"
   ],
   "metadata": {
    "id": "lKXY4Lo0WyoU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "samples_df = pd.DataFrame(forecasts[0].samples.T,\n",
    "                          index=pd.date_range(df['ds'].iloc[-1], periods=24, freq='1h'),\n",
    "                          columns=[f'sample_{i}' for i in range(forecasts[0].samples.shape[0])])\n",
    "\n",
    "# 2. Join with the existing forecast DataFrame\n",
    "samples_df = pd.merge(fcst_df, samples_df, left_on='ds', right_index=True, how='left')\n",
    "\n",
    "plot_series(df, samples_df, max_insample_length=100,\n",
    "            xlabel=\"Hour\", ylabel=\"Price\",\n",
    "            title=\"Electricity price of the Nord Pool electricity market\",\n",
    "            rm_legend=True)\n"
   ],
   "metadata": {
    "id": "GAyfWUbeHF58"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
