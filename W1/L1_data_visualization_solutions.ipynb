{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMUeDbnYSaU8AWJr1R+9lwm",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nepslor/B5203E-TSAF/blob/main/W1/L1_data_visualization_solutions.ipynb)"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Time Series visualization and analysis\n",
    "\n",
    "In this exercise we will go through an example of exploratory analyisis and time series visualization with python. We will usa a dataset containing power measurements and meteorological forecasts relative to a set of **24 power meters** located in Rolle (Switzerland).\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/nepslor/teaching/main/TimeSeriesForecasting/figs/REeL_Demo_grid.png\" width=\"500\"/>\n",
    "\n",
    "The yellow dots in the image shows the positions of the power meters.\n",
    "Besides power readings, the dataset includes **temperatue** and **irradiance** measurements from a local meteo station.\n",
    "\n",
    "Let's start downlowading and looking at the first rows of the dataset:"
   ],
   "metadata": {
    "id": "uM2H8VJ2nNDb"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "0KFPgb-QmWNT",
    "outputId": "e93edeb1-4a05-4626-f410-4777f0243f95"
   },
   "source": [
    "import pandas as pd\n",
    "df_all = pd.read_pickle(\"https://github.com/nepslor/teaching/raw/refs/heads/main/TimeSeriesForecasting/data/power_dataset.pk\")\n",
    "df_all.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# last timestep in the dataset\n",
    "print(df_all.index[-1])\n",
    "\n",
    "# descriptive statistics for the columns in the dataset\n",
    "df_all.describe()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "59ZiWRyiYsFp",
    "outputId": "666ddb75-e6f1-4e9b-b424-16b0bba2df9c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that:\n",
    "* the dataset contains 3 signals, the power and two covariates, irradiance and temperature, possibily useful to predict the power\n",
    "* The datase has hourly timestamps\n",
    "* It start Jan 2018 and ends Jan 2019\n",
    "* Each signals contains 8928 values\n",
    "\n",
    "## Check for missing values and timestamp regularity\n",
    "We can check if data presents some missing values:"
   ],
   "metadata": {
    "id": "bokxB3GT6QXT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_all.isna().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "id": "jazy5zVbpliZ",
    "outputId": "2030823d-783f-43c6-bc71-bdb2ef651d8b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And the distribution of sampling times:"
   ],
   "metadata": {
    "id": "lPM38TqEqU78"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_all.index.diff().value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "BodzqJVdqLk8",
    "outputId": "d12dbf9e-4202-4b77-d62d-c387ffbf9848"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The only present sampling time is 1 hour, this means the series is regularly sampled.\n",
    "\n",
    "## Line plots\n",
    "We can try to plot a subset of the dataset as lineplot via pandas:"
   ],
   "metadata": {
    "id": "xNnD5u0wqZgD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = df_all[['power', 'temperature', 'irradiance']]\n",
    "\n",
    "# simple plot\n",
    "data.plot(figsize=(20, 3))\n",
    "\n",
    "# last 7 days plot\n",
    "data.tail(24*7).plot(figsize=(20, 3))\n",
    "\n",
    "# since signals have different scales, it is useful to plot them in separate axes:\n",
    "data.tail(24*7).plot(figsize=(20, 3), subplots=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "2c9dIUFa5cp6",
    "outputId": "c7ea61f9-177d-48d7-be5b-071795aa2537"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot the power meters' readings, filtering the dataset using the `.filter` method and the `like` argument"
   ],
   "metadata": {
    "id": "xGpO3W5jq_9A"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_all.filter(like='meter').plot(figsize=(20, 3), alpha=0.5).legend(ncols=3, loc='upper right')\n",
    "df_all.filter(like='meter').tail(24*7).plot(figsize=(20, 3), alpha=0.5).legend(ncols=3, loc='upper right')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "erajGgnrbWJd",
    "outputId": "84bc23ee-66ef-4295-941d-291f47cc702b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scatter plots\n",
    "\n",
    "We start to do a simple analysis scattering all the signals against each other using the `seaborn` library `pairplot` function. We are also interested in see if the current value of the power is correlated with itself at the previous day. To see this we can use the `panda`'s `shift` method. Note how the first values becom NaNs, since we cannot retrieve past values for the first 24 observations:"
   ],
   "metadata": {
    "id": "mqrLQehb8LdY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# we shift the signal by 24 steps\n",
    "data['power'].shift(24)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "6Vqe-1xF8iiJ",
    "outputId": "6e12b4c6-3b96-46a2-d710-55ac173c9984"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use the `.assign` method that temporarly adds a column to the dataframe and scatter all the 4 variables"
   ],
   "metadata": {
    "id": "nLrOTHxJ5ZKy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.pairplot(data.assign(power_lag24=data['power'].shift(24)),\n",
    "            plot_kws={\"s\": 3, \"alpha\":0.2})\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "V1kV3RhF7i2x",
    "outputId": "33f70656-da11-48c4-84e1-96a3208d38ae"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "❓ **which patterns/relations can you spot between these variables?**\n",
    "\n"
   ],
   "metadata": {
    "id": "FeNRH8BHG1jT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can try to visualize the relationship of the signal with itself at increasing lags by producing a set of scatter polots, here from 1 to 48:  "
   ],
   "metadata": {
    "id": "3Nh7VGrmIUx4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Lag Animation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Initialize the scatter plot\n",
    "x = data['power']\n",
    "y = data['power'].shift(1)\n",
    "sc = ax.scatter(x, y, s=1, alpha=0.5)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Power')\n",
    "ax.set_ylabel('Power Lag')\n",
    "ax.set_title('Scatter Plot of Power vs. Power Lag')\n",
    "\n",
    "# despine axes\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Animation update function\n",
    "def update(frame):\n",
    "    k = frame + 1\n",
    "    sc.set_offsets(list(zip(data['power'], data['power'].shift(k))))  # Update the scatter plot data\n",
    "    ax.set_ylabel(f'Power Lag {k}')\n",
    "    # compute correlation\n",
    "    ax.set_title(f'Scatter Plot of Power vs. Power Lag {k}')\n",
    "    return sc,\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update, frames=48, blit=True, interval=80, repeat=True)\n",
    "plt.close(fig)\n",
    "# Display the animation in HTML5\n",
    "HTML(ani.to_jshtml())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "cellView": "form",
    "id": "Va5j_gXUk0rc",
    "outputId": "78a1a374-38de-4744-970b-28070a862233"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Auto covariance function\n",
    "This information can be summarized by plotting just the **linear dependence** of the signal with its previous lags, the autocorrelation function.\n",
    "\n",
    "$$\\begin{align}\\rho_k = \\frac{cov(x_t, x_{t-k})}{\\sigma(x_t)\\sigma(x_{t-k})}\n",
    "\\stackrel{stationary}{=}& \\frac{cov(x_t, x_{t-k})}{\\sigma^2(x)}\\\\\n",
    "\\stackrel{sampling}{=}& \\frac{\\sum_{t=1}^{t=T-k} (x_t-\\hat{\\mu}_x) (x_{t -k}-\\hat{\\mu}_x)}{T \\hat{\\sigma}_x}\n",
    "\\end{align}$$\n",
    "where\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\mu}_x &= \\frac{1}{T} \\sum_{t=1}^T x_t \\qquad \\qquad \\ \\ \\  \\color{green}{\\text{df.mean()}} \\\\\n",
    "\\hat{\\sigma}_x &= \\frac{1}{T} \\sum_{t=1}^T (x_t-\\hat{\\mu}_x)^2 \\qquad \\color{green}{\\text{df.std()}}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "❓ **Try to code the autocorrelation function using the .shift method**\n",
    "\n",
    "You can define it as `acf = lambda x, k: your code here`"
   ],
   "metadata": {
    "id": "qjIkVOA4V6R4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "acf = lambda x, k: ((x.shift(k)-x.mean())*(x-x.mean())).sum() / x.std()**2 / len(x)"
   ],
   "metadata": {
    "id": "6ChDSdgkXF6N"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "plot_acf(data['power'], lags=24*8, ax=ax, label='statsmodels ACF');\n",
    "plt.plot([acf(data['power'], k) for k in range(24*8)], label='our ACF')\n",
    "plt.grid()\n",
    "plt.ylim(-0.25, 1)\n",
    "plt.legend(loc='lower right');"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "qbFvnB6FkZOn",
    "outputId": "6e40aae7-b469-4f19-8d11-7fdfce5a2103"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Strong seasonalities can be spotted at 24 hours intervals, with a second local maximum after 7 days (the second dashed vertical line), indicating a strong weekly seasonality.\n",
    "\n",
    "\n",
    "## Embeddings\n",
    "We can now try to use the two local maxima (24 and 24*7 steps) as embedding for the time series, and try to see if the signal show eveident patterns.\n",
    "Loosly speaking the following chain holds:\n",
    "\n",
    "                        patterns -->  compressibility --> forecastability\n",
    "\n",
    "The idea: if we reshape the signal with the maxima of the ACF we can plot it as a matrix, making patterns evident."
   ],
   "metadata": {
    "id": "ivNkt49onOeP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "daily_power = data.assign(                            # assign method temporaly adds new features to a dataframe\n",
    "    day=data.index.date,\n",
    "    hour=data.index.hour\n",
    ").pivot(index='hour', columns='day', values='power')  # pivot create a matrix from \"index\" and \"columns\"\n",
    "\n",
    "# plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "sb.heatmap(daily_power, cmap='viridis', ax=ax)\n",
    "ax.set_title('Daily power consumption')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "gywnDIKsnftF",
    "outputId": "6aebc78b-2acb-4123-f258-fd8c345e97ba"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# the dataset spans more than one year, \"week\" index is not unique ->\n",
    "# -> we use pivot_table which average observations falling in the same index-column bin\n",
    "weekly_power = data.assign(\n",
    "    week=data.index.isocalendar().week,\n",
    "    weekhour= data.index.hour + data.index.dayofweek * 24\n",
    ").pivot_table(index='weekhour', columns='week', values='power')\n",
    "\n",
    "# plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "sb.heatmap(weekly_power, cmap='viridis', ax=ax)\n",
    "ax.set_title('Daily power consumption')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "cDXHwNzbqljW",
    "outputId": "f4412a9c-c576-4dfd-8e78-9fff52cfb017"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "❓ **Try to obtain the same plots for temperature and irradiance. What do you observe?**"
   ],
   "metadata": {
    "id": "PmQFna_40Qwt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "daily_t = data.assign(\n",
    "    day=data.index.date,\n",
    "    hour=data.index.hour\n",
    ").pivot(index='hour', columns='day', values='temperature')\n",
    "\n",
    "daily_irradiance = data.assign(\n",
    "    day=data.index.date,\n",
    "    hour=data.index.hour\n",
    ").pivot(index='hour', columns='day', values='irradiance')\n",
    "\n",
    "# plot heatmap\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 6))\n",
    "sb.heatmap(daily_t, cmap='viridis', ax=ax[0])\n",
    "sb.heatmap(daily_irradiance, cmap='viridis', ax=ax[1])\n",
    "plt.tight_layout()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "mv9tz-josYb1",
    "outputId": "a724666b-72ae-42f6-b446-bf8575d98de8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# get the day of the week of each column\n",
    "dow = data.assign(day=data.index.date,\n",
    "      hour=data.index.hour,\n",
    "      dayofweek=data.index.dayofweek).pivot(index='hour',\n",
    "                                            columns='day',\n",
    "                                            values='dayofweek').mean()\n",
    "\n",
    "daily_power.loc[:,dow<5].plot(color='pink', alpha=0.3, legend=False)\n",
    "daily_power.loc[:,dow>=5].plot(color='r', alpha=0.3, legend=False, ax=plt.gca())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "uAyMwan01PrR",
    "outputId": "d537584c-6ffe-4861-d399-b6aba5f6b5d9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ❓Some exploratory analysis\n",
    "* Among the bottom time series, find the most similar and most dissimilar couples\n",
    "* Look at the most dissimilar couple. Try to scatter them against the values of the predicted GHI\n",
    "* Can you spot other series for which the GHI has a similar effect?\n"
   ],
   "metadata": {
    "id": "VaW_-Nh_b5eJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bottom_series = df_all.filter(like='meter')\n",
    "corrcoeffs = np.corrcoef(bottom_series.values.T)\n",
    "plt.matshow(corrcoeffs)\n",
    "plt.title('correlation matrix')\n",
    "\n",
    "# to find the most similar timeseries we set nan the diagonal entries of the coorelation matrix (the correlation of a given timeseries with itself)\n",
    "corrcoeffs[corrcoeffs>=.9999] = np.nan\n",
    "anti_idx_1, anti_idx_2 = np.where(corrcoeffs==np.nanmin(corrcoeffs))\n",
    "corr_idx_1, corr_idx_2 = np.where(corrcoeffs==np.nanmax(corrcoeffs))\n",
    "\n",
    "fig,ax = plt.subplots(2, 1, figsize=(20, 6))\n",
    "ax[0].plot(bottom_series.iloc[:, [anti_idx_1[0], anti_idx_2[0]]].values)\n",
    "ax[1].plot(bottom_series.iloc[:, [corr_idx_1[0], corr_idx_2[0]]].values)\n",
    "ax[0].set_title('least correlated data')\n",
    "ax[1].set_title('most correlated data')\n",
    "\n",
    "# print indexes of most correlated couples\n"
   ],
   "metadata": {
    "id": "J3k-9JzNJcsC",
    "outputId": "31a855a3-a301-4f74-8b36-9994e959d8bc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax[0].scatter(data['irradiance'], bottom_series.iloc[:, anti_idx_1[0]].values, s=2, alpha=0.2)\n",
    "ax[0].set_xlabel('GHI')\n",
    "ax[0].set_ylabel(bottom_series.columns[anti_idx_1[0]])\n",
    "ax[0].set_title('Least Correlated Series 1 vs. GHI')\n",
    "\n",
    "ax[1].scatter(data['irradiance'], bottom_series.iloc[:, anti_idx_2[0]].values, s=2, alpha=0.2)\n",
    "ax[1].set_xlabel('GHI')\n",
    "ax[1].set_ylabel(bottom_series.columns[anti_idx_2[0]])\n",
    "ax[1].set_title('Least Correlated Series 2 vs. GHI')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "wo5FWd3L7x6V",
    "outputId": "7e1eb3af-a3a5-4fc5-fdbc-abeda355b17b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We try to plot series correlating the most with GHI and also the most anti-correlated"
   ],
   "metadata": {
    "id": "fTNp5UeM7UgH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# find the singals correlating the most with ghi\n",
    "ghi_corr = [np.corrcoef(data['irradiance'], bottom_series.iloc[:, i])[0, 1] for i in range(bottom_series.shape[1])]\n",
    "dissimilar_meters_idx = np.argsort(ghi_corr)[:3]\n",
    "similar_meters_idx = np.argsort(ghi_corr)[-3:]\n",
    "indexes = [dissimilar_meters_idx, similar_meters_idx]\n",
    "\n",
    "# let's focus ourselves on a summer month\n",
    "time = data['irradiance'].index\n",
    "july_filter = (time.month==7) & (time.day>=1) & (time.day<=6)\n",
    "\n",
    "# plot the most correlated and anti-correlated meters with GHI in the month of July\n",
    "for i in range(2):\n",
    "  idxs = indexes[i]\n",
    "  plt_data = pd.concat([data['irradiance'].loc[july_filter], bottom_series.loc[july_filter].iloc[:,idxs]], axis=1)\n",
    "  plt_data.plot(figsize=(15, 5), subplots=True)\n",
    "\n",
    "\n",
    "# scatter the most correlated and anti-correlated meters with GHI in the month of July\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for i in range(2):\n",
    "  idxs = indexes[i]\n",
    "  [ax[i].scatter(data['irradiance'].loc[july_filter], bottom_series.iloc[july_filter, s], alpha=0.8, s=1) for s in idxs]\n",
    "ax[0].set_title('Least Correlated Series vs. GHI')\n",
    "ax[1].set_title('Most Correlated Series vs. GHI')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "id": "i9H9dwqgvAq-",
    "outputId": "df098c52-2121-471e-f1f5-79f44c93d243",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "What are we seeing?\n",
    "* It looks like some meters strongly unti-correlate in the month of July with radiation: those are the meters for which consumption reduces when radiation increases. This could mean PV panels are installed there.\n",
    "* A segond group shows strong correlation with GHI in the month of July. This could mean some air conditioning system is installed there, increasing the cooling need when the radiation is higher"
   ],
   "metadata": {
    "id": "sJd8bHmu7fjZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BONUS: forecasting by whithening\n",
    "In the following we will explore a powerful method to produce probabilistic forecasts of a time series.  \n",
    "\n",
    "Idea: **if we can make the TS ~white noise through transformations, we can predict it by sampling from the noise and inverting the transform**\n",
    "\n",
    "Matematically, if\n",
    "$$f_1(f_2(..f_n(x))) \\quad \\sim \\text{i.i.d.} \\quad \\mathcal{N}(0, \\sigma)$$\n",
    "then\n",
    "$$\\hat{x}_{t:t+h} = f_n^{-1}(f_{n-1}^{-1}(..f_1^{-1}(\\mathcal{N}(0, \\sigma))))$$\n",
    "\n"
   ],
   "metadata": {
    "id": "VQQU_V4uYQpb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# let's start by splitting the time series in a training and a test set\n",
    "p_tr = data['power'].iloc[:-24]\n",
    "p_te = data['power'].iloc[-24:]\n"
   ],
   "metadata": {
    "id": "j68DkunTM9Mu"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "we will apply just two transformations: difference from previous week values and difference from previous step"
   ],
   "metadata": {
    "id": "8ykdZdTkb8zw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "p_week_diff = p_tr.diff(24*7)\n",
    "p_week_diff_1 = p_week_diff.diff(1)\n",
    "\n",
    "# plot histograms of p_tr and the other two transfomations\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 3))\n",
    "p_tr.plot.hist(ax=axs[0], bins=50, alpha=0.5, label='p_tr')\n",
    "p_week_diff.plot.hist(ax=axs[1], bins=50, alpha=0.5, label='p_week_diff')\n",
    "p_week_diff_1.plot.hist(ax=axs[2], bins=50, alpha=0.5, label='p_week_diff_1')\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "# plot ACF functions for all the three signals\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 3))\n",
    "plot_acf(p_tr, lags=24*8, ax=axs[0], label='p_tr')\n",
    "plot_acf(p_week_diff.dropna(), lags=24*8, ax=axs[1], label='p_week_diff')\n",
    "plot_acf(p_week_diff_1.dropna(), lags=24*8, ax=axs[2], label='p_week_diff_1')\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "(p_tr).tail(24*30).plot()\n",
    "p_week_diff.tail(24*30).plot()\n",
    "p_week_diff_1.tail(24*30).plot()\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930
    },
    "id": "Ic57R8ZsZwqb",
    "outputId": "17b5a467-a95b-4e65-b96b-9b9dcf176702"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(100):\n",
    "  p_hat =  p_tr.iloc[-24*7:-24*6] + np.random.choice(p_week_diff_1, 24).cumsum()  # values of previous week + integrated samples of p_week_diff_1\n",
    "  p_hat.index = p_te.index\n",
    "  p_hat.plot(color='r', alpha=0.3, linewidth=0.5)\n",
    "\n",
    "\n",
    "# plot the forecast and some hisory\n",
    "(p_tr).tail(24*14).plot(figsize=(15, 5))\n",
    "p_week_diff.tail(24*14).plot()\n",
    "p_week_diff_1.tail(24*14).plot()\n",
    "p_te.plot(color='k', linewidth=2)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "vXp5OB0wZx17",
    "outputId": "3cadace9-31d6-4d33-9aab-cf7d670f6ca3"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
