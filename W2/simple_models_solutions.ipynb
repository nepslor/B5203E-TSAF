{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nepslor/B5203E-TSAF/blob/main/W2/simple_models_solutions.ipynb)"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple forecasting models and stochastic processes tests\n",
    "In this exercise we will use ACF, portmaneau tests and stationarity tests to understand if a time series can be easily forecasted.\n",
    "\n",
    "We start by analysing time series in terms of correlation of close timesteps. Using the ACF and stationarity tests is possible to understand whether a time series is similar to a white noise process.\n",
    "White noise-like processes have two contrastin properties when it comes to forecasting:\n",
    "* stationarity: properties of the signal sucha as mean and variance can almost surely be estimated\n",
    "* aleatoric updates: this make forecasting a specific timestep extremely challenging\n"
   ],
   "metadata": {
    "id": "xIaCjG6vWGbt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ],
   "metadata": {
    "id": "EcGPxbsTpNVo"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's plot some time series and their ACF with associated static confidance bands for the IID test we crafted during the lecture. Do you agree with what the ACFs suggest?"
   ],
   "metadata": {
    "id": "eD9bNjhcK1jP"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "-SugtcgDBbhi",
    "outputId": "9877129b-abf3-4d8c-9bad-e16c67e03977"
   },
   "source": [
    "dfs = pd.read_pickle('https://github.com/nepslor/teaching/raw/refs/heads/main/TimeSeriesForecasting/data/ts_datasets.pk')\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 6))\n",
    "for a, df in zip(ax.ravel(), dfs):\n",
    "    df.plot(ax=a)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(20, 6))\n",
    "for a, df in zip(ax.ravel(), dfs):\n",
    "    plot_acf(df.values.ravel(), lags=24, zero=False, bartlett_confint=False, ax=a,title=df.columns[0])\n",
    "    a.set_ylim(-0.5, 1.2)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "0JU88C3dH78f",
    "outputId": "31211089-bcd0-4d4d-f4ea-cea7bd219f43"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stationarity tests\n",
    "We report here the two main tests for stationarity:\n",
    "\n",
    "\n",
    "| Test    | H0 | H1 |\n",
    "| --------| ------- | ------- |\n",
    "| ADF     | The series is  non-stationary  |  stationary     |\n",
    "| KPSS    | The series is  trend-stationary |  non-stationary  |\n",
    "\n"
   ],
   "metadata": {
    "id": "J7oeOt0nT3oK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "stationarity_tests = {}\n",
    "for a, df in zip(ax.ravel(), dfs):\n",
    "    adf_test = adfuller(df.values.ravel())\n",
    "    kpss_test = kpss(df.values.ravel())\n",
    "    stationarity_tests[df.columns[0]] = pd.Series({'adf pval': adf_test[1], 'kpss pval': kpss_test[1]})\n",
    "\n",
    "\n",
    "pd.concat(stationarity_tests).unstack().sort_values('adf pval')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "r4ZO13WnPMJT",
    "outputId": "8dbf8610-13f2-41bf-df19-f1682b09fcbc"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ❓ Code the simple forecasting methods we have seen during the last lecture\n",
    "\n",
    "Write 1-line functions for the following simple forecasting methods\n",
    "\n",
    "* naive:$$\\hat{y}_{T+h \\mid T}=y_T$$\n",
    "* mean: $$\\hat{y}_{T+h \\mid T}=\\bar{y}=\\left(y_1+\\cdots+y_T\\right) / T$$\n",
    "* seasonal naive: $$\\hat{y}_{T+h \\mid T}=y_{T+h-m(k+1)}$$\n",
    "\n",
    "the forecasts accept as input the time series up to the last timestep, $[x_{t}]_{t=0}^T$ and the parameter $h$ indicating the number of steps ahead to be predicted.\n"
   ],
   "metadata": {
    "id": "TZt3byx_2jm-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def cast_df(y, df):\n",
    "    h = len(y)\n",
    "    return pd.DataFrame(y, index=np.arange(len(df), len(df)+h))\n",
    "\n",
    "\n",
    "# code the three naive methods that we've seen\n",
    "naive = lambda x, h: cast_df(np.tile(x.iloc[-1], h), x)\n",
    "mean = lambda x, h: cast_df(np.tile(x.mean(), h), x)\n",
    "p = 12\n",
    "seasonal = lambda x, h: cast_df(np.tile(x.iloc[-p:].values.ravel()-x.iloc[-p:].values[0]+x.iloc[-p:].values[-1], int(p*np.ceil(h/p)))[:h], x)\n",
    "\n",
    "\n",
    "# forecast all the datasets and test on the last 24 steps\n",
    "forecasters = [naive, mean, seasonal]\n",
    "forecasers_names = ['naive', 'mean', 'seasonal']\n",
    "steps_ahead = 24\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 8))\n",
    "for a, df in zip(ax.ravel(), dfs):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df_tr, df_te = df.iloc[:-steps_ahead], df.iloc[-steps_ahead:]\n",
    "    steps_ahead = 24\n",
    "    forecasts = {}\n",
    "    for f, n in zip(forecasters, forecasers_names):\n",
    "        forecasts[n] = f(df_tr, steps_ahead)\n",
    "    [a.plot(v, label=k) for k, v in forecasts.items()]\n",
    "    df_te.plot(ax=a)\n",
    "    df_tr.iloc[-steps_ahead*3:].plot(ax=a)\n",
    "    a.legend()"
   ],
   "metadata": {
    "id": "Vr-bqE1HpeO6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "outputId": "a1e8a1de-1772-4770-c22e-080731b46864"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieve the normalized mean absolute error in CV\n",
    "We can define the nMAE as $$nMAE =  \\frac{\\frac{1}{h}\\sum_{t=T}^{T+h} \\vert y_t -\\hat{y}_t  \\vert}{\\frac{1}{h}\\sum_{t=T}^{T+h} (y_t-\\bar{y})}$$\n",
    "This function gives an idea of the forecasting error over the whole prediction horizon, normalized by the variance of the signal over the h. Since it's normalized by how much the signal varies in the forecasting period, should be a good metric to compare different signals in terms of \"how good\" we are at forecasting them.\n",
    "\n",
    "❓ Write a 1-line function for the nMAE and retrieve errors for all the combinations of forecasters and datasets in CV\n",
    "\n"
   ],
   "metadata": {
    "id": "5uYbnF063VjJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# define nmae\n",
    "nmae = lambda x, y: np.mean(np.abs(x-y)) / np.std(x)\n",
    "\n",
    "n_prediction_steps = 70\n",
    "steps_ahead = 24\n",
    "nmaes_df = {}\n",
    "errors_df_1_sa = {}\n",
    "for df in dfs:\n",
    "    errors = []\n",
    "    nmaes = []\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    for i in range(n_prediction_steps):\n",
    "        df_i = df.iloc[:steps_ahead*2 + i]\n",
    "        df_tr, df_te = df_i.iloc[:-steps_ahead], df_i.iloc[-steps_ahead:]\n",
    "        forecasts = {n: f(df_tr, steps_ahead) for f, n in zip(forecasters, forecasers_names)}\n",
    "        errors.append({n: (df_te.values.ravel()[0] - forecast.values.ravel()[0]) for n, forecast in forecasts.items()})\n",
    "        nmaes.append({n: nmae(df_te.values, forecast) for n, forecast in forecasts.items()})\n",
    "    nmaes_df[str(df.columns[0])] = pd.DataFrame(nmaes)\n",
    "    errors_df_1_sa[str(df.columns[0])] = pd.DataFrame(errors)\n",
    "errors_df_1_sa = pd.concat(errors_df_1_sa, axis=1)\n",
    "nmaes_df = pd.concat(nmaes_df, axis=1)\n",
    "\n",
    "errors_df_1_sa"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "GtdOryuUpoGQ",
    "outputId": "0f280140-32fd-4a44-bf21-527e650cf465"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's now plot the nMAE for different methods and different signals. What do you notice?\n"
   ],
   "metadata": {
    "id": "6P3RSzzjMqmr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "nmaes_df.mean().unstack().sort_values('naive').plot(kind='bar',  figsize=(10, 5))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "0wFuq0D4FIe_",
    "outputId": "cd5d0eb8-3bd8-40fd-d6d0-ca0e88618cd2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Portmanteau tests on the residual\n",
    "Let's try another method to compare how good we are at forecasting each signal. We are now interested in the autocorrelation propoerties of the residual (error).\n",
    "In particular, if the error time series is uncorrelated (similar to white noise) we are almost sure no further information can be extracted from it to forecast the signal itself. Conversely, if the error seems autocorrelated, it means we could fit a secon model on it to improve the forecast (or directly improve the existing one)."
   ],
   "metadata": {
    "id": "A42ajKc2NqMb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "series_names = errors_df_1_sa.columns.get_level_values(0).unique()\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 6))\n",
    "for a, series_name in zip(ax.ravel(), series_names):\n",
    "    errors_df_1_sa[series_name]['naive'].plot(ax=a)\n",
    "    a.set_title(series_name)\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 6))\n",
    "for a, series_name in zip(ax.ravel(), series_names):\n",
    "    plot_acf(errors_df_1_sa[series_name]['naive'].values.ravel(), lags=24, zero=False, bartlett_confint=False, ax=a,title=series_name)\n",
    "    a.set_ylim(-0.5, 1.2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IJmHvE2IHCaU",
    "outputId": "f8fb1eec-54d8-4750-945d-df9702dbccaa"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "pqEMAbRyOXxm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import statsmodels.api as sm\n",
    "tests = []\n",
    "for series_name in series_names:\n",
    "  results = sm.stats.acorr_ljungbox(errors_df_1_sa[series_name]['naive'].values, lags=[10], return_df=True)\n",
    "  results.index = [series_name]\n",
    "  tests.append(results)\n",
    "\n",
    "pd.concat(tests).sort_values('lb_pvalue')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "IfqVSjkqGD9Q",
    "outputId": "acbd7ebf-8686-4088-d1a6-77a9f08237c4"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
