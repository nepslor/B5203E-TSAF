{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nepslor/B5203E-TSAF/blob/main/W7/arima_models_solutions.ipynb)\n",
    "# ARIMA models\n",
    "In this exercise we will\n",
    "* define an AR model using recursive strategy to predict\n",
    "* define a direct linear forecaster using the same inputs\n",
    "* rely on external libraries to tune ARIMA models"
   ],
   "metadata": {
    "id": "YvHt7b7ZpqBW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install statsforecast>=1.0.0\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "NuH3RZBaYUS7"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gmxjEiqY_3AZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "45039205-c329-448c-97ae-9a939df642ae"
   },
   "source": [
    "df_tunnel = pd.read_csv('https://raw.githubusercontent.com/nepslor/teaching/main/TimeSeriesForecasting/data/tunnel.csv', parse_dates=True, index_col=0)\n",
    "df_tunnel.index = pd.DatetimeIndex(df_tunnel.index, freq='D')\n",
    "print(df_tunnel.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_tunnel.plot(figsize=(10, 3))\n",
    "\n",
    "# plot acf function for df_tunnel\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_acf(df_tunnel, lags=40, ax=ax);"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "2Gt8InouAXqR",
    "outputId": "7ce38959-fa00-456e-8702-f63c308dd400"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AR models\n",
    "Auto regressive models can be defined as:\n",
    "$$y_t = \\sum_{i \\in \\mathcal{I}}  y_{t-i}\\phi_i + \\varepsilon_t $$\n",
    "where $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma)$. This is a slightly different definition w.r.t. the one we introduce during the lecture ($y_t = \\sum_{i=1}^{p}  y_{t-i}\\phi_i + \\varepsilon_t$) which assumed that the features used as regressors are **consecutive** previous steps of the process. As we recall from the exercise on the Taken's theorem, could be worth it to investigare non-uniformly sampled lags as model's feature. That's where the notation $i \\in \\mathcal{I}$ in the summation comes from: this refers to a generic set of lags $\\mathcal{I}$ that are not necessarily consecutive.\n",
    "Examples for this set could be:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{I} &= [1, 2, 3] \\\\\n",
    "\\mathcal{I} &= [1, 3, 6, 9] \\\\\n",
    "\\mathcal{I} &= [1, 2, 24, 48]\n",
    "\\end{aligned}\n",
    "$$\n"
   ],
   "metadata": {
    "id": "viDOxEMqDcsR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def format_data(y:pd.Series, covariate_lags:list, target_lags:list=None):\n",
    "\n",
    "  \"\"\"\n",
    "  Format data for autoregressive model\n",
    "  \"\"\"\n",
    "  x = []\n",
    "  target = []\n",
    "  for i in np.sort(covariate_lags)[::-1]:\n",
    "    y_lagged = y.shift(i)\n",
    "    y_lagged.rename(columns={y_lagged.columns[0]: 'y_{:02d}'.format(i)}, inplace=True)\n",
    "    x.append(y_lagged)\n",
    "  x = pd.concat(x, axis=1).dropna()\n",
    "\n",
    "  if target_lags is not None:\n",
    "    for i in target_lags:\n",
    "      y_lagged = y.shift(i)\n",
    "      y_lagged.rename(columns={y_lagged.columns[0]: 'y_{:02d}'.format(i)}, inplace=True)\n",
    "      target.append(y_lagged)\n",
    "    target = pd.concat(target, axis=1)\n",
    "    df = pd.concat({'x':x, 'target':target}, axis=1)\n",
    "    df = df.dropna()\n",
    "    x = df['x']\n",
    "    target = df['target']\n",
    "\n",
    "  return x, target\n",
    "\n",
    "x, y = format_data(df_tunnel, covariate_lags=[1, 2, 3], target_lags=[0])\n",
    "\n",
    "x.iloc[:20].plot(figsize=(10, 3))\n",
    "y.iloc[:20].plot(ax=plt.gca(), color='black', linestyle='--', title='features and target');"
   ],
   "metadata": {
    "id": "tzjc4E_gDb4E",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "outputId": "c77bb665-af56-4f9e-8f71-8c8f57c2b810"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AR models\n",
    "In the following you can find an implementation of a simple AR model.\n",
    "The model is completely defined by the parameter `covariate_lags`, which is a list defining the set $\\mathcal{I}$.\n",
    "\n",
    "\n",
    "The parameters are fitted minimizing the usual sum of square loss on the one step ahead prediction:\n",
    "$$ \\begin{aligned}\n",
    "\\phi^* = &\\text{arg}\\min_{\\phi} \\Vert y-  \\sum_{i \\in \\mathcal{I}}  y_{t-i}\\phi_i\\Vert_2^2\\\\\n",
    "=&\\text{arg}\\min_{\\phi} \\Vert y-  x\\phi\\Vert_2^2 \\\\\n",
    "=&(x^Tx)^{-1}(x^Ty)\n",
    "\\end{aligned}$$\n",
    "\n",
    "The prediction is then obtained using the recursive strategy $\\hat y_{t+2} = f(\\hat y_{t+1})$\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/nepslor/B5203E-TSAF/raw/95ab6491476169ca761b47d1bee8735b12346694/pics/recursive_forecast.png\" width=\"400\">\n"
   ],
   "metadata": {
    "id": "uoyZjerA7hvf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class AR_forecaster:\n",
    "  covariate_lags:list = [1, 2, 3]\n",
    "  theta:np.array=None\n",
    "  def __init__(self, covariate_lags=[1]):\n",
    "    self.covariate_lags = covariate_lags\n",
    "    self.theta = np.zeros(len(covariate_lags))\n",
    "\n",
    "  def fit(self, y:pd.Series):\n",
    "    # obtain the lags defining the model's features\n",
    "    x, y = format_data(y, covariate_lags=self.covariate_lags, target_lags=[-1])\n",
    "    # fit the parameters\n",
    "    self.theta = np.linalg.inv(x.values.T @ x.values) @ x.values.T @ y.values\n",
    "    return self\n",
    "\n",
    "  def predict(self, y:pd.Series, steps_ahead=1):\n",
    "    # recursive prediction: at each step the model predicts one step ahead\n",
    "    # the prediction is then used as last observation\n",
    "    y_pred = []\n",
    "    x_i, _ = format_data(y, covariate_lags=self.covariate_lags)\n",
    "    x_i = x_i.iloc[[-1], :].values\n",
    "\n",
    "    for i in range(steps_ahead):\n",
    "      # prediction step\n",
    "      y_pred_i = x_i @ self.theta\n",
    "      # store the prediction\n",
    "      y_pred.append(y_pred_i)\n",
    "      # recursive strategy - augment and roll the feature vector\n",
    "      x_i = np.hstack([x_i, y_pred_i])\n",
    "      x_i = x_i[:, 1:]\n",
    "    return pd.Series(np.hstack(y_pred).ravel(), index=pd.date_range(start=y.index[-1]+pd.Timedelta(days=1), periods=steps_ahead, freq='D'))\n"
   ],
   "metadata": {
    "id": "s6kvQ0AP3dM2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing different models\n",
    "\n",
    "The following function fits the AR model on a training set and then performs sliding window predictions. You can use this to evaluate different models and find the best combinations of lags."
   ],
   "metadata": {
    "id": "l1dZ0asuqK9b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model_class, y, steps_ahead, tr_ratio=0.8, **model_kwargs):\n",
    "  n_tr = int(len(y)*tr_ratio)\n",
    "  n_val = len(y) - n_tr\n",
    "  y_tr = y.iloc[:n_tr]\n",
    "  model = model_class(**model_kwargs).fit(y_tr)\n",
    "  y_hats = []\n",
    "  errs = []\n",
    "  for i in range(n_val-steps_ahead):\n",
    "    y_hat_i = model.predict(y.iloc[:n_tr+i], steps_ahead=steps_ahead).values\n",
    "    y_hats.append(y_hat_i)\n",
    "    y_true_i = y.iloc[n_tr+i:n_tr+i+steps_ahead].values.ravel()\n",
    "    errs.append((y_hat_i - y_true_i))\n",
    "  y_hats = np.vstack(y_hats)\n",
    "  errs = np.vstack(errs)\n",
    "  score = np.mean((np.mean(np.abs(np.array(errs)), axis=1)))\n",
    "  return score, y_hats, errs\n",
    "\n",
    "tr_ratio = 0.8\n",
    "steps_ahead = 14\n",
    "score, y_hat, errs = evaluate_model(AR_forecaster, df_tunnel,\n",
    "                                    covariate_lags=np.arange(7),\n",
    "                                    steps_ahead=steps_ahead,\n",
    "                                    tr_ratio=tr_ratio)\n",
    "print('AR model score:{:0.2e}'.format(score))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0Jyk09b3pl_",
    "outputId": "46ee0ebe-5e38-40a7-ee14-3b19a7e3cd80"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Animation\n",
    "# create an animation plotting each row of y_hat and y_te\n",
    "from matplotlib import animation\n",
    "n_tr = int(len(df_tunnel)*tr_ratio)\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "def animate(y_hats, y_all):\n",
    "\n",
    "  def animate(i):\n",
    "    ax.clear()\n",
    "    ax.plot(y_hats[i], label='y_hat')\n",
    "    ax.plot(y_all.iloc[n_tr+i:n_tr+i+steps_ahead].values, label='y_te')\n",
    "    ax.legend(loc='upper left')\n",
    "    return ax,\n",
    "\n",
    "  ani = animation.FuncAnimation(fig, animate, frames=100, interval=80)\n",
    "  from IPython.display import HTML\n",
    "  plt.close(fig)\n",
    "  return HTML(ani.to_jshtml())\n",
    "\n",
    "animate(y_hat, df_tunnel)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "M3KpApEf6aX_",
    "outputId": "b8c2571b-1ab9-453a-92fc-e9a57324af21",
    "cellView": "form"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check the autocorrelation of the 1-step-ahead predictions:"
   ],
   "metadata": {
    "id": "pnx23xykS77P"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# check autocorrelation of the errors 1 step ahead\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_acf(errs[:, 0], lags=40, ax=ax);"
   ],
   "metadata": {
    "id": "p9MFR-UwRGrk",
    "outputId": "1b6631c6-f367-4ac0-aa2d-a3d6e66331b4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ❓ Find the best number of covariates\n",
    "We can explore the effect of increasing the number of past timesteps used by the AR forecaster:"
   ],
   "metadata": {
    "id": "Z82wm5ixTA4D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "n_tr = int(len(df_tunnel)*0.5)\n",
    "y_tr = df_tunnel.iloc[:n_tr]\n",
    "y_te = df_tunnel.iloc[n_tr:]\n",
    "\n",
    "y_tr.iloc[-100:].plot()\n",
    "for i in [5, 6, 7, 8, 120]:\n",
    "  ar_model = AR_forecaster(covariate_lags=range(i)).fit(df_tunnel)\n",
    "  ar_model.predict(y_tr, steps_ahead=21).plot(figsize=(10, 3),ax=plt.gca(), label='order {}'.format(i))\n",
    "plt.legend(loc='lower left')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "8OeBbHP0Dtrb",
    "outputId": "3373abef-7a63-466b-868c-0768f8190027"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ❓Direct AR forecaster\n",
    "The following block defines a direct autoregressive forecaster, which predicts all the covariates in one shot. Since we are using a linear regression there's no need to fit n_sa different models, we just need to pass a multi-column target.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/nepslor/B5203E-TSAF/raw/95ab6491476169ca761b47d1bee8735b12346694/pics/direct_forecast.png\" width=\"400\">\n",
    "\n",
    "Fill in the missing line"
   ],
   "metadata": {
    "id": "_9qwC1LwqqoG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class direct_forecaster:\n",
    "  covariate_lags:list = [1, 2, 3]\n",
    "  theta:np.array=None\n",
    "  steps_ahead:int = 1\n",
    "  def __init__(self, covariate_lags=[1],steps_ahead=1):\n",
    "    self.covariate_lags = covariate_lags\n",
    "    self.theta = np.zeros(len(covariate_lags))\n",
    "    self.steps_ahead = steps_ahead\n",
    "\n",
    "  def fit(self, y:pd.Series):\n",
    "    # obtain the lags defining the model's features\n",
    "    x, y = format_data(y, covariate_lags=self.covariate_lags, target_lags=-np.arange(1, steps_ahead+1))\n",
    "    # fit the parameters\n",
    "    self.theta = np.linalg.inv(x.values.T @ x.values) @ x.values.T @ y.values\n",
    "    return self\n",
    "\n",
    "  def predict(self, y:pd.Series, steps_ahead=1):\n",
    "    # recursive prediction: at each step the model predicts one step ahead\n",
    "    # the prediction is then used as last observation\n",
    "    y_pred = []\n",
    "    x_i, _ = format_data(y, covariate_lags=self.covariate_lags)\n",
    "    x_i = x_i.iloc[[-1], :].values\n",
    "    # direct forecast\n",
    "    y_pred = x_i @ self.theta\n",
    "    return pd.Series(y_pred.ravel(), index=pd.date_range(start=y.index[-1]+pd.Timedelta(days=1), periods=steps_ahead, freq='D'))\n",
    "\n",
    "score, y_hat, errs = evaluate_model(direct_forecaster, df_tunnel,\n",
    "                                    covariate_lags=np.arange(14),\n",
    "                                    steps_ahead=steps_ahead,\n",
    "                                    tr_ratio=tr_ratio)\n",
    "print('AR model score:{:0.2e}'.format(score))\n",
    "\n",
    "animate(y_hat, df_tunnel)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "DjjgtWwbQqe8",
    "outputId": "a5443def-0dac-4bed-bdd4-3013664c6cc4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_acf(errs[:, 0], lags=40, ax=ax);"
   ],
   "metadata": {
    "id": "xduTvufVRub7",
    "outputId": "55f981cf-48eb-4ad9-cbab-cf862a41db38",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from statsforecast.models import AutoARIMA\n",
    "from statsforecast.core import StatsForecast\n",
    "from functools import partial\n",
    "\n",
    "class Model_wrap(AutoARIMA):\n",
    "  def __init__(self, **kwargs):\n",
    "    # super init\n",
    "    super().__init__(**kwargs)\n",
    "\n",
    "  def predict(self, y, steps_ahead):\n",
    "    return pd.Series(self.forward(y, h=steps_ahead)['mean'])\n",
    "\n",
    "\n",
    "# change the format to nixta compatible\n",
    "df_tunnel_nixtla = df_tunnel.reset_index()\n",
    "df_tunnel_nixtla.columns = ['ds', 'y']\n",
    "score, y_hat, errs = evaluate_model(partial(Model_wrap, season_length=14, stepwise=False),\n",
    "                                    df_tunnel_nixtla['y'],\n",
    "                                    steps_ahead=steps_ahead,\n",
    "                                    tr_ratio=tr_ratio)\n",
    "print('AR model score:{:0.2e}'.format(score))\n",
    "\n",
    "animate(y_hat, df_tunnel)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "xUilNGUjG7yi",
    "outputId": "f3b1591d-2ea6-4a58-82cb-19d65bc72340"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_acf(errs[:, 0], lags=40, ax=ax);"
   ],
   "metadata": {
    "id": "E4Ihj4zTRvWf",
    "outputId": "8007dfcc-ad70-4343-f3c4-4017f577aea6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ❓ Try to beat the benchmarks\n",
    "Using either the given implementation of the AR model and the direct forecaster or the sktime pipeline, try to beat the proposed models in terms of MAE by tuning the models parameters.\n",
    "\n"
   ],
   "metadata": {
    "id": "YMGFwHEpoKtC"
   }
  }
 ]
}
